{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+u/6dtLvJEGumCmQ/eWEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orcascope/spark_play/blob/main/setup_spark_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkYT6K7Bp2T5",
        "outputId": "62259d69-8d2f-4e60-9803-ef3cd2ecbc2e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Github/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrIjg86XqYUs",
        "outputId": "3198ce57-d65f-4ff3-d5c5-4fc1eeafd4f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf .git\n",
        "!git clone https://github.com/orcascope/spark_play"
      ],
      "metadata": {
        "id": "bwltLOPWcM48",
        "outputId": "468ced92-33a9-422f-f16d-c6b88d3d4ba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spark_play'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 15 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (15/15), 1.17 MiB | 4.35 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd spark_play"
      ],
      "metadata": {
        "id": "smV4oALvc4H0",
        "outputId": "9094f4cf-055b-493f-fda5-121cfb9387d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Github/spark_play\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhBhrGmyAvs"
      },
      "source": [
        "!apt-get -qq update > /tmp/apt.out\n",
        "!apt-get install -y -qq openjdk-11-jdk-headless"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!(wget -q --show-progress -nc https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz)\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32LLPBQpij-w",
        "outputId": "aa7d4fb0-28f3-4f85-fc5d-17f48061b808"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.2.1-bin-had 100%[===================>] 287.03M  11.6MB/s    in 27s     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF-e1DAsGUaL"
      },
      "source": [
        "try:\n",
        "  import pyspark, findspark, delta, pyngrok\n",
        "except:\n",
        "  %pip install -q --upgrade pyspark==3.2.1\n",
        "  %pip install -q findspark\n",
        "  %pip install -q delta\n",
        "  %pip install pyngrok"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pass the config k,v pairs and get a spark session object"
      ],
      "metadata": {
        "id": "7CBeyfwbK61a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "import pyspark\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/drive/MyDrive/Github/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "findspark.init()\n",
        "MAX_MEMORY=\"8g\"\n",
        "maven_coords = [\n",
        "    \"org.apache.spark:spark-avro_2.12:3.2.1\",\n",
        "    \"io.delta:delta-core_2.12:2.0.0rc1\",\n",
        "    \"org.xerial:sqlite-jdbc:3.36.0.3\",\n",
        "    \"graphframes:graphframes:0.8.2-spark3.2-s_2.12\",\n",
        "    \"com.acervera.osm4scala:osm4scala-spark3-shaded_2.12:1.0.8\",\n",
        "]\n",
        "spark = (pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
        "    .config(\"spark.jars.packages\", \",\".join(maven_coords))\n",
        "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
        "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
        "    .config(\"spark.executor.memory\", MAX_MEMORY)\n",
        "    .config(\"spark.driver.memory\", MAX_MEMORY)\n",
        "    .config('spark.ui.port', '4050')\n",
        "    .enableHiveSupport()\n",
        "    .getOrCreate()\n",
        "    )\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "nyXkqLzrjJ1c",
        "outputId": "ed4df675-29f3-4c79-d59e-2eeee5bdd1ae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c473408b1f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - hive</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://e8e47bc71cba:4050\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>MyApp</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "print(\"Enter your authtoken, which can be copied \"\n",
        "\"from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "\n",
        "ui_port = 4040\n",
        "public_url = ngrok.connect(ui_port).public_url\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{ui_port}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dqyNpYQTDIM",
        "outputId": "02e254f3-6ac5-4613-b5cf-1956318ec998"
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n",
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-06-15T14:39:21+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://50f0-34-68-94-133.ngrok-free.app\" -> \"http://127.0.0.1:4040\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup is complete. At this point you have started a spark application and able to access the application-ui using the url above.\n",
        "You can start writing your data transformation code below..."
      ],
      "metadata": {
        "id": "PFIP7ijrWE6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spark SQL API: Create a temporary view from the csv data source in spark_play/netflix_titles.csv.\n",
        "\n",
        "Use spark.sql(\"query\") to access the view with SQL syntax"
      ],
      "metadata": {
        "id": "ci1lwBBrJ56s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"csv\").option(\"header\", \"true\").load('./spark_play/netflix_titles.csv').createOrReplaceTempView(\"movies\")\n",
        "spark.sql(\"select * from movies limit 5\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKhh4iy3dAax",
        "outputId": "4263ca16-e6e0-416a-f792-b7b095c6fb71"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
            "|show_id|   type|title|         director|                cast|      country|       date_added|release_year|rating| duration|           listed_in|         description|\n",
            "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
            "|     s1|TV Show|   3%|             null|João Miguel, Bian...|       Brazil|  August 14, 2020|        2020| TV-MA|4 Seasons|International TV ...|In a future where...|\n",
            "|     s2|  Movie| 7:19|Jorge Michel Grau|Demián Bichir, Hé...|       Mexico|December 23, 2016|        2016| TV-MA|   93 min|Dramas, Internati...|After a devastati...|\n",
            "|     s3|  Movie|23:59|     Gilbert Chan|Tedd Chan, Stella...|    Singapore|December 20, 2018|        2011|     R|   78 min|Horror Movies, In...|When an army recr...|\n",
            "|     s4|  Movie|    9|      Shane Acker|Elijah Wood, John...|United States|November 16, 2017|        2009| PG-13|   80 min|Action & Adventur...|In a postapocalyp...|\n",
            "|     s5|  Movie|   21|   Robert Luketic|Jim Sturgess, Kev...|United States|  January 1, 2020|        2008| PG-13|  123 min|              Dramas|A brilliant group...|\n",
            "+-------+-------+-----+-----------------+--------------------+-------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pyspark dataframe API: Create a dataframe from the csv data source\n",
        "\n",
        "Use pyspark syntax to do data transformation"
      ],
      "metadata": {
        "id": "hVL7FkRMKctL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = spark.read.format(\"csv\").option(\"header\", \"true\").load('./spark_play/netflix_titles.csv')\n",
        "movies_df.show()"
      ],
      "metadata": {
        "id": "EcOcsqJHKtyR",
        "outputId": "395de8e5-085e-4136-838a-f23a1e0614c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+------+--------------------+--------------------+--------------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
            "|show_id|   type| title|            director|                cast|             country|       date_added|release_year|rating| duration|           listed_in|         description|\n",
            "+-------+-------+------+--------------------+--------------------+--------------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
            "|     s1|TV Show|    3%|                null|João Miguel, Bian...|              Brazil|  August 14, 2020|        2020| TV-MA|4 Seasons|International TV ...|In a future where...|\n",
            "|     s2|  Movie|  7:19|   Jorge Michel Grau|Demián Bichir, Hé...|              Mexico|December 23, 2016|        2016| TV-MA|   93 min|Dramas, Internati...|After a devastati...|\n",
            "|     s3|  Movie| 23:59|        Gilbert Chan|Tedd Chan, Stella...|           Singapore|December 20, 2018|        2011|     R|   78 min|Horror Movies, In...|When an army recr...|\n",
            "|     s4|  Movie|     9|         Shane Acker|Elijah Wood, John...|       United States|November 16, 2017|        2009| PG-13|   80 min|Action & Adventur...|In a postapocalyp...|\n",
            "|     s5|  Movie|    21|      Robert Luketic|Jim Sturgess, Kev...|       United States|  January 1, 2020|        2008| PG-13|  123 min|              Dramas|A brilliant group...|\n",
            "|     s6|TV Show|    46|         Serdar Akar|Erdal Beşikçioğlu...|              Turkey|     July 1, 2017|        2016| TV-MA| 1 Season|International TV ...|A genetics profes...|\n",
            "|     s7|  Movie|   122|     Yasir Al Yasiri|Amina Khalil, Ahm...|               Egypt|     June 1, 2020|        2019| TV-MA|   95 min|Horror Movies, In...|After an awful ac...|\n",
            "|     s8|  Movie|   187|      Kevin Reynolds|Samuel L. Jackson...|       United States| November 1, 2019|        1997|     R|  119 min|              Dramas|After one of his ...|\n",
            "|     s9|  Movie|   706|       Shravan Kumar|Divya Dutta, Atul...|               India|    April 1, 2019|        2019| TV-14|  118 min|Horror Movies, In...|When a doctor goe...|\n",
            "|    s10|  Movie|  1920|        Vikram Bhatt|Rajneesh Duggal, ...|               India|December 15, 2017|        2008| TV-MA|  143 min|Horror Movies, In...|An architect and ...|\n",
            "|    s11|  Movie|  1922|        Zak Hilditch|Thomas Jane, Moll...|       United States| October 20, 2017|        2017| TV-MA|  103 min|   Dramas, Thrillers|A farmer pens a c...|\n",
            "|    s12|TV Show|  1983|                null|Robert Więckiewic...|Poland, United St...|November 30, 2018|        2018| TV-MA| 1 Season|Crime TV Shows, I...|In this dark alt-...|\n",
            "|    s13|TV Show|  1994|Diego Enrique Osorno|                null|              Mexico|     May 17, 2019|        2019| TV-MA| 1 Season|Crime TV Shows, D...|Archival video an...|\n",
            "|    s14|  Movie| 2,215| Nottapon Boonprakob|  Artiwara Kongmalai|            Thailand|    March 1, 2019|        2018| TV-MA|   89 min|Documentaries, In...|This intimate doc...|\n",
            "|    s15|  Movie|  3022|          John Suits|Omar Epps, Kate W...|       United States|   March 19, 2020|        2019|     R|   91 min|Independent Movie...|Stranded when the...|\n",
            "|    s16|  Movie|Oct-01|      Kunle Afolayan|Sadiq Daba, David...|             Nigeria|September 1, 2019|        2014| TV-14|  149 min|Dramas, Internati...|Against the backd...|\n",
            "|    s17|TV Show|Feb-09|                null|Shahd El Yaseen, ...|                null|   March 20, 2019|        2018| TV-14| 1 Season|International TV ...|As a psychology p...|\n",
            "|    s18|  Movie|22-Jul|     Paul Greengrass|Anders Danielsen ...|Norway, Iceland, ...| October 10, 2018|        2018|     R|  144 min|   Dramas, Thrillers|After devastating...|\n",
            "|    s19|  Movie|15-Aug|  Swapnaneel Jayakar|Rahul Pethe, Mrun...|               India|   March 29, 2019|        2019| TV-14|  124 min|Comedies, Dramas,...|On India's Indepe...|\n",
            "|    s20|  Movie|   '89|                null|Lee Dixon, Ian Wr...|      United Kingdom|     May 16, 2018|        2017| TV-PG|   87 min|       Sports Movies|Mixing old footag...|\n",
            "+-------+-------+------+--------------------+--------------------+--------------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From a dataframe, Write to a Delta table"
      ],
      "metadata": {
        "id": "EGemGhX0LMOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from delta.tables import DeltaTable\n",
        "import delta\n",
        "\n",
        "df = spark.createDataFrame([{'s':'hello world','i':1234}])\n",
        "\n",
        "(df.write.format('delta')\n",
        "         .mode('overwrite')\n",
        "         .option(\"mergeSchema\", \"true\")\n",
        "         .save('./delta_hello_world')\n",
        ")\n"
      ],
      "metadata": {
        "id": "magAGym1jM40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read back the data from the delta Table. Here spark sql api is used to read."
      ],
      "metadata": {
        "id": "ngHKDSpNLbWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.read.format(\"delta\").load('./delta_hello_world').createOrReplaceTempView(\"delta_hello_world\")\n",
        "df2 = spark.sql(\"\"\"\n",
        "  select * from delta_hello_world\n",
        "\"\"\")\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-Guj5fywDJt",
        "outputId": "173891ad-5521-4b2a-d700-a1a27492fb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+\n",
            "|   i|          s|\n",
            "+----+-----------+\n",
            "|1234|hello world|\n",
            "+----+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}